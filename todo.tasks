{"deleted":true,"desc":"","last_edited":1761718291351,"position":-20.75,"task_id":"7fcbdf13-607d-4e0f-a064-4593e6b7d26e"}
{"deleted":true,"desc":"3\\) Debounce your “micro\\-sync complete” rescan\n\nYour log shows it firing twice per batch. If that’s your own scheduler, consider debouncing per phase so you trigger once at the end of the merge.\n\n","last_edited":1761510330797,"position":-4.4375,"task_id":"ced0b724-16fa-48a9-ba24-994232903e2b"}
{"deleted":true,"desc":"delete chunks in parallel?\n","last_edited":1761542700125,"position":-4.8125,"task_id":"c2def45a-0248-41e8-8b22-3634be95d7f3"}
{"desc":"#0 #easy show the syncroot digests in session status\n","done":true,"last_edited":1761934551890,"position":-39.9375,"task_id":"2a72ac83-b7b7-4d1c-a4f7-98577dacf7cc"}
{"desc":"#0 #now  Make it so names can be used instead of ids in cli commands, where if the input is an integer that equals an existing id.   How about require names to not be an integer as the only requirement (so we can instantly decide \"id\" or \"name\"?) and also requires names to be globally unique.\n\nBasically right now when creating a new sync session a user can optionally specify a name for that session.  The point of the name is that it makes it easier to refer to the session in other cli commands.  Thus it makes a lot of sense that anywhere one can use <id>, a name would also work.  If we make names also have to satisfy \"not an integer\"  and globally unique, it should be very easy to parse this unambiguously.","done":true,"last_edited":1762016538764,"position":-48.1875,"task_id":"fbc22d75-a962-4abc-b7d1-2b617bd6eabb"}
{"desc":"#0 RFSYNC_ --> REFLECT_\n\nsrc/session-status.ts:  const staleMs = Number(process.env.SESSION_STALE_MS ?? 15_000);\nsrc/session-db.ts:  const xdg = process.env.XDG_DATA_HOME;\nsrc/session-db.ts:    const appData = process.env.APPDATA || join(home, \"AppData\", \"Roaming\");\nsrc/session-db.ts:    const keepMs = Number(process.env.HEARTBEAT_KEEP_MS ?? 0);\nsrc/session-db.ts:    const keepRows = Number(process.env.HEARTBEAT_KEEP_ROWS ?? 7200);\nsrc/session-cli.ts:    env: process.env,\nsrc/session-logs.ts:  const raw = process.env[key];\nsrc/micro-sync.ts:  const ECHO_SUPPRESS_MS = Number(process.env.MICRO_ECHO_SUPPRESS_MS ?? 2500);\nsrc/constants.ts:export const MAX_WATCHERS = Number(process.env.CFSYNC_MAX_WATCHERS ?? 128);\nsrc/scheduler.ts:  process.env[k] ? Number(process.env[k]) : def;\nsrc/scheduler.ts:  const HEARTBEAT_MS = Number(process.env.HEARTBEAT_MS ?? 2000);\nsrc/ingest-delta.ts:const SAFETY_MS = Number(process.env.CLOCK_SKEW_SAFETY_MS ?? 100);\nsrc/ingest-delta.ts:const FUTURE_SLACK_MS = Number(process.env.FUTURE_SLACK_MS ?? 400);\nsrc/ingest-delta.ts:const CAP_BACKOFF_MS = Number(process.env.FUTURE_CAP_BACKOFF_MS ?? 1);","done":true,"hideBody":true,"last_edited":1762019331441,"position":-46.5,"task_id":"9cfa4c16-2906-4179-b672-c94da64100a5"}
{"desc":"#0 ability to edit certain properties of sessions:\n\nNext lets implement the ability to edit certain properties of a session!   E.g.,\n\nreflect edit <id-or-name> --property=value [...]\n  \nThe properties I can think of that don't require a session reset are:\n\n- compress\n- ignore list \\(once in db?\\)\n  \nIgnore isn't implemented at all, except via a file.  I would like it to be implemented via a field in the database instead of a file.    The way to specify it would be\n  \n   reflect create /tmp/a /tmp/b --ignore=foo --ignore=\n  \n  - ignore=... (zero or more times repeated, each adds a rule)\n  - --no-ignore = when passed in resets the ignore rules\n  \n  \n- anything else would require a full session reset (so maybe a --reset flag)\n   - hash function\n   - alpha or beta\n\n\nreflect edit <id-or-name> --property=value\n  \n  where the options for property are:\n  \n  - compress\n  - ignore=... (zero or more times repeated, each adds a rule)\n  - --no-ignore = when passed in resets the ignore rules\n  \nThen these three require that the --reset flag is also passed in:\n  \n  - hash=\n  - alpha=\n  - beta=\n\n","last_edited":1762037309015,"position":-51.5625,"task_id":"ad182af7-139e-4b55-9dfe-6c7e8205ffef"}
{"desc":"#0 ccsync session reset\n","done":true,"last_edited":1762017283024,"position":-49.1875,"task_id":"a902f752-410a-4828-8c97-43d1da3cf216"}
{"desc":"#0 cli \\-\\- flush \\-\\- use that digests are equal on both sides would give us total confidence.\n","last_edited":1761929501332,"position":-50.5625,"task_id":"c4c9c766-b292-4027-9490-b5e11f197676"}
{"desc":"#0 cli jest integration tests would be very good to have!","last_edited":1762017496258,"position":-46.5625,"task_id":"95a4ed3f-58d5-4333-8482-dc90d9b364a1"}
{"desc":"#0 confusion between \"paused\" and \"stopped\":\n\n```sh\nwstein@lite:~/build/reflect-sync$ reflect create -p /tmp/a /tmp/c -l foo=bar\ncreated session 4\nwstein@lite:~/build/reflect-sync$ reflect list\n╭──────────────────────────────────────────────────────────────────────────────╮\n│                                   Sessions                                   │\n├────┬─────────┬────────────────────────┬────────┬────────┬──────────┬─────────┤\n│ ID │  Name   │ State (actual/desired) │ Prefer │ Alpha  │   Beta   │   PID   │\n├────┼─────────┼────────────────────────┼────────┼────────┼──────────┼─────────┤\n│ 2  │ tmp-a-b │ paused/paused          │ alpha  │ /tmp/a │ /tmp/b   │ 2689878 │\n│ 3  │ remote  │ paused/paused          │ alpha  │ /tmp/a │ s:/tmp/a │ 2735913 │\n│ 4  │ -       │ stopped/stopped        │ alpha  │ /tmp/a │ /tmp/c   │ -       │\n╰────┴─────────┴────────────────────────┴────────┴────────┴──────────┴─────────╯\n```","done":true,"hideBody":false,"last_edited":1762019339890,"position":-46.4375,"task_id":"b66b6690-c0ec-4364-a7aa-4de693ecce10"}
{"desc":"#0 create a daemon \\-\\- key thing is it monitors and autostarts sessions.\n\nCreate a reflect-sync daemon, which:\n\n- runs as a background daemon and ensures all sync sessions that are supposed to be running (according to the database are actually running).\n- start it running via \"reflect-sync daemon start\" (no-op if already running)\n- stop it via \"reflect-sync daemon stop\"\n\nIt would also be good to have a way to \"install\" the daemon for a user so it gets automatically started if it isn't running.   Mutagen itself automaticallyed modified my ~/.bashrc when I first used it:\n\n```\nwstein@lite:~/build/reflect-sync$ rg mutagen ~/.bashrc \n142:/usr/local/bin/mutagen daemon start\n```\n\nHowever, regarding autoinstalling of the daemon, whatever we do should be \"what users expect\" and pretty standard.  It only needs to work on macos/linux.  \n\nI am open to using a library for the daemonization (as long as it is rock solid and pure javascript).    \n\nWhat do you think? ","done":true,"last_edited":1762027725633,"position":-47.5625,"task_id":"808f2485-3bb2-4692-9ccc-fb52abebb5ec"}
{"desc":"#0 exclude config path automatically  \\-\\- .local/share/reflect\\-sync\n\nif user sync's HOME then get a feedback loop (?).\n","last_edited":1762002162311,"position":-47.5625,"task_id":"ad38ed91-826f-419e-8ff1-3e238a6a0d0f"}
{"desc":"#0 much better observability, e.g., rsync progress, what exactly is happening with sessions, etc., history\n\nBasically the goal here is that each stage of sync that could take a while will provide some sort of good updates to our really nice existing log system about what is going on.  These can then be read (in json) and rendered by other frontend clients (which are NOT part of this project).   I think we're in very good shape to be able to provide useful progress to the log, because we usually know exactly what files we're copying/deleting, how many there are, and how big they are.  The situations where I think good progress information is critical are:\n\n- when doing an rsync of files as part of the main sync loop from alpha to beta or beta to alpha.  It would be very nice to provide log entries that show progress at a roughly 3 second resolution interval (that could be configurable).  I know rsync has various --progress options, but I know nothing about how they interact with using an explicit-file list -- hopefully you do? \n\n- same as the above, but for hot updates also involving rsync.\n\n- for \"cp --reflink\" it's so fast no progress updates are needed.  Basically updates on a single machine (where neither sync root is remote) are not mostly not needed, unless rsync is being used.\n\n- when doing scanning one could have progress updates, but maybe that's not reasonable or viable, since we don't know how many files there will be, so can't say anything meaningful.    However, we could slightly restructure the scan code to do the full scan (filling in entries in the database), and THEN start computing the hashes via webworkers -- if we did that it would be slightly slower, but we could provide very good progress information while doing the hash scan.  Can we change to do this?  I think it would be worth it to divide the scan stage into two in order to ensure we have excellent progress info. \n\nI think that's about it.   What do you think?","last_edited":1762028285711,"position":-49.5625,"task_id":"3dd34736-0885-4324-aaf0-7dc8765623ad"}
{"desc":"#0 replace the ignore _file_ by database configuration. It's critical it be same on both sides so digest matches up, and it feels like database is the right place.\n","last_edited":1762002241933,"position":-48.5625,"task_id":"c7e05ee7-85f6-4b0e-89ed-1b8ebb31bfab"}
{"desc":"#0 restart","last_edited":1762037087586,"position":-50.3125,"task_id":"f93ac988-99b0-4c43-b14b-dd433b5ed7b0"}
{"desc":"#0 support ports in the syncroot spec and everywhere else.\n\n \n  I would like to support specify a remote ssh port in the notation for specifying the sync roots alpha and beta.  Right now the only way to  do this is using ~/.ssh/config and having an alias there, which was the only option with mutagen (which reflect-sync will compete with).  I would like to have another option with reflect-sync to specify a remote port, which is reasonably easy to use and understand.    The simplest user-friendly idea might be like this to specify that the remote port is 2222.\n  \n  reflect create /tmp/a  remote-server:2222:/tmp/b\n  \nIf the user does\n\n  reflect create /tmp/a  remote-server::/tmp/b\n  \nor \n\n  reflect create /tmp/a  remote-server:/tmp/b\n\nthen it is the default port 22.\n\nThis feels familiar and easy to use, since it's similar to http and also using a separate \"-p\" option is a bit painful since it isn't clearly tied to either sync root (alpha or beta).  \n\nI realize there is potentially some ambiguity if paths were to contain a colon... but I think since a path can always be given starting with \"/\" or \"~/\" (at least on posix) it's not so bad.     \n\nI realize that actually implementing port support for ssh will take quite a bit of care since there are many places where we call rsync and ssh, and passing ports in can be tricky (e.g., for rsync over ssh).    It'll fortunately be easy to manually test though, assuming the code is actually right. (Automated testing is trickier since it would require spinning up a little ssh server temporarily or a port forward locally...?) \n\nDo you see any issues with this design/plan?\n\n","done":true,"last_edited":1762023558881,"position":-47.5625,"task_id":"87998d7b-313f-4484-a03e-caf5595b411d"}
{"desc":"#0 when creating a paused session the database files are NEVER created anywhere? \\(true but makes no sense yet\\)\n","done":true,"last_edited":1762027830807,"position":-32,"task_id":"1d3989d7-8221-44d3-bca6-024f557a4120"}
{"desc":"#1 #dist #sea macos signed binaries\n","last_edited":1761929554107,"position":1.625,"task_id":"809d1dd4-46bc-4c02-9dc0-67d0a5010d51"}
{"desc":"#1 #dist build a static rsync \\(since it's often very old etc on some systems\\), and I can see now exactly how to add that as an asset and copy it out if needed to ~/.cocalc/reflect\\-sync.\n","last_edited":1761929546846,"position":1.125,"task_id":"f911c19e-356b-4219-b966-236a457c06dc"}
{"desc":"#1 #idea can we use our database to do internal file\\-level dedup on a COW filesystem?  i.e., scan the db and when there are two files A and B with the same hash, do something to identify them if they are really equal.  I don't know if this can be safely done \"online\", or how big of a saving it would be in general... but it's worth considering.\n","last_edited":1761759310457,"position":-0.375,"task_id":"d25a5266-7ec7-411d-982a-3a4b4b761dda"}
{"desc":"#1 #sea #dist package rsync as a static binary with sea\n","last_edited":1761929496513,"position":0.625,"task_id":"e5973dff-3f08-4082-8010-8018e4941001"}
{"desc":"#1 #speed moves?\n\n- can be done but quite complicated\n- i made a moves branch\n\n","last_edited":1761717956259,"position":0.125,"task_id":"2c9fd2c3-6a58-47c1-b4f6-d35596c1ec16"}
{"desc":"#1 more stress testing \\(large randomized sync runs\\)\n","last_edited":1761929507172,"position":-2.15625,"task_id":"f9ce7c5f-2f27-4c2c-be12-3832f1186c71"}
{"desc":"#easy #0 session terminate needs to delete remote db\n\n","done":true,"last_edited":1761955714105,"position":-41.6875,"task_id":"407276fd-b22b-427c-9185-2d80b4d7fb3b"}
{"desc":"#now #0 #easy make \"reflect list\" look pretty, similar to \"reflect status\" (i.e., using ascii-table3 with same options).\n\nHere's another task that is probably pretty easy. Right now the output of \"reflect list\" is kind boring/ugly:\n\n```sh\nwstein@lite:~/build/reflect-sync$ reflect list\nid=2  name=tmp-a-b  state=paused/paused  prefer=alpha  alpha=/tmp/a  beta=/tmp/b  pid=2689878\nid=3  name=remote  state=paused/paused  prefer=alpha  alpha=/tmp/a  beta=s:/tmp/a  pid=2735913\nwstein@lite:~/build/reflect-sync$ \n```\n\nIn contrast the output of \"reflect status 3\" is pretty using ascii-table3:\n\n```sh\nwstein@lite:~/build/reflect-sync$ reflect status 3\n╭─────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│                                          Session 3: remote                                          │\n├─────────────────┬───────────────────────────────────────────────────────────────────────────────────┤\n│      Field      │                                       Value                                       │\n├─────────────────┼───────────────────────────────────────────────────────────────────────────────────┤\n│ name            │ remote                                                                            │\n│ alpha           │ /tmp/a                                                                            │\n│ beta            │ s:/tmp/a                                                                          │\n│ prefer          │ alpha                                                                             │\n│ hash            │ sha256                                                                            │\n│ compress        │ auto                                                                              │\n│ base db         │ ~/.local/share/reflect-sync/sessions/3/base.db                                    │\n│ alpha db        │ ~/.local/share/reflect-sync/sessions/3/alpha.db                                   │\n│ beta db         │ ~/.local/share/reflect-sync/sessions/3/beta.db                                    │\n│ beta remote db  │ s:~/.local/share/reflect-sync/by-origin/d7Z9fYgQQIy1XvfRpzdWmg/sessions/3/beta.db │\n│ created         │ 2 hours ago on Sat Nov 01 2025 06:55:09 GMT-0700 (Pacific Daylight Time)          │\n│ [digest]        │ 6 minutes ago ✅  (synchronized)                                                   │\n│ [digest] alpha  │ yyJTURbZNRSv774pJAxgPRURtawEosvhXEWoRomUpI4=                                      │\n│ [digest] beta   │ yyJTURbZNRSv774pJAxgPRURtawEosvhXEWoRomUpI4=                                      │\n│ status          │ stopped                                                                           │\n│ pid             │ 2735913                                                                           │\n│ host            │ lite                                                                              │\n│ running         │ yes                                                                               │\n│ pending         │ no                                                                                │\n│ cycles          │ 317                                                                               │\n│ errors          │ 0                                                                                 │\n│ last heartbeat  │ 6 minutes ago                                                                     │\n│ last cycle      │ 1.49 s                                                                            │\n│ backoff         │ -                                                                                 │\n│ started         │ 2025-11-01T13:55:11.015Z                                                          │\n│ stopped         │ 2025-11-01T16:30:24.779Z                                                          │\n│ health          │ stopped                                                                           │\n╰─────────────────┴───────────────────────────────────────────────────────────────────────────────────╯\n\n```\n\nThat's implemented in session-status.ts.   Can you make \"reflect list\" also look similarly nice (and consistent with session-status) using that ascii table library?","done":true,"last_edited":1762015651262,"position":-47.1875,"task_id":"ed76fc0f-54c0-4482-9ae4-b37925177f9b"}
{"desc":"#now #0 #easy show location of config/data files for sync session\n","done":true,"last_edited":1761935430370,"position":-39.8125,"task_id":"7150b47a-97fd-4076-9bc1-276c66ee0f95"}
{"desc":"#now #0 if creating session fails, delete from database \\(try / catch\\)\n","done":true,"last_edited":1761957299198,"position":-43.6875,"task_id":"d00300fe-0009-437a-be4c-d127345c760a"}
{"desc":"#now #0 reorg cli and make the session commands at the top and the reset hidden under something advanced ?\n\n- put port forward under subcommand though?\n- ReflectPort is a neat name \\-\\- should be its own project!?\n\nLet's tackle this tasks next:\n\n- Reorg CLI (session-first, advanced under subcommands)\n    - Scope: Restructure commands, keep compat aliases.\n    - Where: src/cli.ts, src/session-cli.ts.\n    - Risks: Doc/README updates; tests.\n    - Effort: Medium.\n\nRight now they top-level cli exposes a bunch of technical internal subcommands.  It also has a \"session\" subcommand, which is the only thing people would actually use, thus making it less ergonomic -- you have type \"reflect session create\" (say) instead of \"reflect create\".  \n\nI think the better UI would be that all the cli commands current under session are moved to the top level, and the other advanced top level commands: scan/scheduler/watch/etc. are maybe hidden from the help unless you give a flag like \"reflect help --advanced\" and then you can see them.  I don't know if that is possible with Commander.js.   To actually run those commands it could still be the same, e.g., \"reflect scan\", \"reflect watch\", etc., -- it's just that usually you don't see the help.  \n\nDoes this make sense?  What do you think?\n","done":true,"last_edited":1762014912826,"position":-46.6875,"task_id":"17ee1a76-bdbb-46dd-b8b0-08d34464bec8"}
{"desc":"#now #0 support rsync compression\n","done":true,"last_edited":1761952360045,"position":-30.84375,"task_id":"e41522e8-649f-453c-9952-9e1a302e669b"}
{"desc":"#now #0 switching logging from console.log to use the debug module.\n\n- [x] make logger not use UTC time \\(?\\).\n\nPrompt: Right now all verbose messaging in this project is done by passing various --verbose command line flags around, arguments to functions, and using\n  console.log.  This was great for the first initial version of this project (which we started just a few weeks ago!).  However, I would like to clean up\n  the code and change it do something much better.   This project as you know defines sessions that synchronize files between two endpoints.  It also has\n  scripts that for low level debugging and dev can be run directly.  I really want to make it so the verbose logging can be \"tuned into\" so I can see it for\n  a particular running session, but then ignore it when not interested.  Probably the way to do this would be to move all such logging to NOT use any\n  \"verbose\" flags and command line params, but instead to call some function which either just drops messages in one mode, or puts recent messages in the\n  sqlite database (periodically trimming older messages), then provide a command such as \"reflect session logs <id>\" to see all recent logs or \"reflect\n  session logs -f <id>\" to follow them, similar to what Kubernetes/podman/docker do.     What are your thoughts?   I don't think just using the debug npm\n  module would work for this problem at all, due to the long running processes and wanting to tune in or not.     This sounds good.  One other critical thing is that I would really like to also be able to surface log messages to users in a frontend app, so having a\n  JSON-friendly format and output for the logs command is important.  Another key thing is that we use rsync and also big index scans in various places in\n  the app.  I need to provide some progress updates for those when running (via the log facility would be fine) so I can surface those to users eventually\n  in a web app.  That doesn't have to be implemented as part of this step, but it's important to keep in mind for later (I'm aware that it'll be some work\n  to properly wire in progress for rsync, but totally do-able.).    In any case, let's get going and start your plan!\n\n","done":true,"last_edited":1762011186389,"position":-45.6875,"task_id":"cb48905d-a1a0-4114-a1cd-d2f1645b6fb7"}
{"desc":"#now #bug #0 I tried git clone cocalc on a slower network and eventually it converged, but there were hundreds of microsyncs.  Seems very broken....\n\nThis happens a lot.  Must be a major bug.\n","done":true,"last_edited":1762012990218,"position":-45.6875,"task_id":"c4c0fa8e-1673-4261-914b-3882bb7faf15"}
{"desc":"#now #bug create file on alpha, wiat for it to sync, before next scan delete it from beta.  It was never in the database on the beta side, so the fact it was deleted isn't noticed and now the two sides are inconsistent.\n","done":true,"last_edited":1761708309642,"position":-20.8125,"task_id":"faa82f49-db57-433f-9125-c4e71e6f04ee"}
{"desc":"#now #dist switch to built in sqlite\n\n","done":true,"last_edited":1761757125606,"position":-25.4375,"task_id":"1747e860-6885-42fd-b2d4-266a7cac862e"}
{"desc":"#now #name rename: ccsync \\-\\-&gt; reflectsync\n","done":true,"last_edited":1761862671210,"position":-32.9375,"task_id":"86bee64d-ba4f-4dd5-bbcd-893f4b922e93"}
{"desc":"#now #speed do the two scans in parallel ?\n","done":true,"last_edited":1761680740279,"position":-16.3125,"task_id":"b4303340-ffc6-42b9-bc2e-568619a0143c"}
{"desc":"#now clean up tombstones... and migrate to all relative paths\n","done":true,"last_edited":1761547139095,"position":-5.6875,"task_id":"9ce325e2-8c5e-4b5b-9c85-418c86291a5a"}
{"desc":"#now crash due to ignore\n\n```\ncsync scan --root /home/wstein/scratch/y --db beta.db --verbose\nrunning scan with database =  beta.db\n/home/wstein/build/ccsync/node_modules/.pnpm/ignore@7.0.5/node_modules/ignore/index.js:557\n  throw new Ctor(message)\n        ^\n\nRangeError: path should be a `path.relative()`d string, but got \"../../build/ccsync/dist/\"\n    at throwError (/home/wstein/build/ccsync/node_modules/.pnpm/ignore@7.0.5/node_modules/ignore/index.js:557:9)\n    at checkPath (/home/wstein/build/ccsync/node_modules/.pnpm/ignore@7.0.5/node_modules/ignore/index.js:576:12)\n    at Ignore._test (/home/wstein/build/ccsync/node_modules/.pnpm/ignore@7.0.5/node_modules/ignore/index.js:637:5)\n    at Ignore.ignores (/home/wstein/build/ccsync/node_modules/.pnpm/ignore@7.0.5/node_modules/ignore/index.js:720:17)\n    at HotWatchManager.localIgnoresDir (file:///home/wstein/build/ccsync/dist/hotwatch.js:97:24)\n    at HotWatchManager.isIgnored (file:///home/wstein/build/ccsync/dist/hotwatch.js:107:20)\n    at handler (file:///home/wstein/build/ccsync/dist/hotwatch.js:142:22)\n    at FSWatcher.<anonymous> (file:///home/wstein/build/ccsync/dist/hotwatch.js:167:36)\n    at FSWatcher.emit (node:events:508:28)\n    at FSWatcher.emitWithAll (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/index.js:431:14)\n\nNode.js v24.8.0\n```\n\n","done":true,"hideBody":true,"last_edited":1761611277956,"position":-10.8125,"task_id":"467c1671-344f-4431-b1fc-d12f20a24160"}
{"desc":"#now do NOT setup hot watches unless there is activity as indicated by a recent _mtime_.\n","done":true,"last_edited":1761715251630,"position":-22.8125,"task_id":"8fd5f1bc-07e7-4732-b1fd-144ce0edeef7"}
{"desc":"#now don't publish tests to npmjs\n","done":true,"last_edited":1761758854263,"position":-27.4375,"task_id":"72e825ec-0762-4a21-8c29-d592e77e82e9"}
{"desc":"#now is it possible to use reflink on a single filesystem?\n\n- yes\n- [x] make fast\n- [x] #now also for hot updates\n\n","done":true,"last_edited":1761690637289,"position":-20.3125,"task_id":"3a7fd90a-13dc-4606-a569-e21e8fec5e0f"}
{"desc":"#now make \"syncing a fully built copy of cocalc with all node\\_modules\" rock solid and fast\n","done":true,"last_edited":1761507498793,"position":-4.9375,"task_id":"29cb086f-a649-4c47-a89f-7aa780d159d5"}
{"desc":"#now maybe switch to a hash in libcrypto after all... even though it costs more cpu, or see what the options are more for something that doesn't have a binary dependency.\n\n- [ ]size idea \\-\\- make hash field in database more compact?\n\n","done":true,"last_edited":1761884370357,"position":-31.9375,"task_id":"d3f54d13-2c06-44ab-a615-cb6ab8babd9b"}
{"desc":"#now multiple remote watches which don't get killed properly and waste resources.\n","done":true,"last_edited":1761712383448,"position":-21.8125,"task_id":"cbd05b79-8230-41a9-bedf-ab268e7f949a"}
{"desc":"#now propagate uid/gid using numeric ids \\-\\- but ONLY if user is uid=0.\n","done":true,"last_edited":1761673805020,"position":-12.8125,"task_id":"25d2f344-f73c-421e-8488-55aad5da4865"}
{"desc":"#now quiet fast path\n","done":true,"last_edited":1761510314398,"position":-5.9375,"task_id":"dd5f63a1-a0fe-4a40-999b-88c774b40a0d"}
{"desc":"#now symlink loop\n","done":true,"last_edited":1761595269899,"position":-8.8125,"task_id":"1390aca8-d622-4bee-b1aa-7cc84f840dfb"}
{"desc":"#now symlink scan problems\n","done":true,"last_edited":1761671652269,"position":-12.5625,"task_id":"a38d3f7d-57b6-457b-bf6c-868486b9747f"}
{"desc":"#now vacuuming \n\n- [x] local\n- [x] remote vacuum \\- add a \"\\-\\-vacuum\" option to scan and pass that when called on remote\n- [x] deleting paths from remote table \\- add \"delete\\-after\\-....\" option to scan.\n\n","done":true,"last_edited":1761717911042,"position":-21.0625,"task_id":"401bf297-7f96-46bc-aecb-50989e60b91f"}
{"desc":"#speed add other operations to microSync:\n\n- [ ] actually fully read the new micro\\-sync.ts carefully\n- directory creation/removal\n- symlinks creation/removal\n- file removal\n\n","done":true,"last_edited":1761845775605,"position":-31.4375,"task_id":"6e77ec92-5ab5-416e-8757-578abe78884c"}
{"desc":"#today sea binary\n\n- [x] need to fix calling .js paths\n- [x] silence rollup warnin\n\n","done":true,"last_edited":1761890339172,"position":-36.9375,"task_id":"7d99ed5d-484c-491a-bb71-e02ed1f0db62"}
{"desc":"#unclear #0 remote reflect\\-sync command: if attempt to run fails, use remoteWhich to figure out exact path, then use exact path until it doesn't work.   when setting up session figure out the path .\n\n- [ ] if remote \\(or local\\) scan fails... shouldn't start deleting all files, but that's definitely what happens.  We need to be better about deciding when a file is deleted.\n- [x] switch to discovering path to remote command\n- [x] the webworker in the bundle doesn't work at all yet either\n\n","last_edited":1762027750497,"position":-47.0625,"task_id":"4ecc8aac-1312-48c1-a42e-5215a173a57b"}
{"desc":"I think at least one query for the merge plan scales very badly. super slow on a built cocalc...?\n\n","done":true,"last_edited":1761502618785,"position":-1.9375,"task_id":"1670b2bd-2366-4d7c-bb92-9b6bd4ba7940"}
{"desc":"big worry \\-\\- if there are two sessions with the same remote beta \\(different alpha\\), and they have the same id, they will store the remotedb in the same place.  NOT good at all.   We'll have to sort this out, but I'm not sure how. Options:\n\n- switch from a sequential numeric id for the session back to a random hash \\(like mutagen uses\\). that easily solves the problem.\n- actually, i can't think of anything better that works in general.\n\n","done":true,"last_edited":1761845848161,"position":-30.1875,"task_id":"75d789d7-f013-424f-8e15-bc5bf5290051"}
{"desc":"ccsync session &lt;command to show where state files are&gt;\n\n","done":true,"last_edited":1761771757768,"position":-28.4375,"task_id":"6ce01cf0-4135-4159-b13f-2c0c339bee4d"}
{"desc":"crash when try to watch something and permission is denied!\n\n```sh\nrsync -a -I --relative --from0 --files-from=/tmp/micro-plan-Y3XayJ/toAlpha.list /home/wstein/scratch/y/ /home/wstein/scratch/x/\nℹ️ [scheduler] event-triggered rescan scheduled: micro-sync complete \nnode:internal/fs/watchers:254\n    const error = new UVException({\n                  ^\n\nError: EACCES: permission denied, watch '/home/wstein/scratch/y/pytorch/pytorch:2.8.0-cuda12.9-cudnn9-runtime/lib/ssl/private'\n    at FSWatcher.<computed> (node:internal/fs/watchers:254:19)\n    at watch (node:fs:2539:36)\n    at createFsWatchInstance (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/handler.js:126:16)\n    at setFsWatchListener (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/handler.js:171:19)\n    at NodeFsHandler._watchWithNodeFs (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/handler.js:325:22)\n    at NodeFsHandler._handleDir (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/handler.js:546:27)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async NodeFsHandler._addToNodeFs (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/handler.js:591:26)\nEmitted 'error' event on FSWatcher instance at:\n    at FSWatcher._handleError (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/index.js:534:18)\n    at NodeFsHandler._addToNodeFs (file:///home/wstein/build/ccsync/node_modules/.pnpm/chokidar@4.0.3/node_modules/chokidar/esm/handler.js:623:26)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5) {\n  errno: -13,\n  syscall: 'watch',\n  code: 'EACCES',\n  path: '/home/wstein/scratch/y/pytorch/pytorch:2.8.0-cuda12.9-cudnn9-runtime/lib/ssl/private',\n  filename: '/home/wstein/scratch/y/pytorch/pytorch:2.8.0-cuda12.9-cudnn9-runtime/lib/ssl/private'\n}\n\nNode.js v24.8.0\nwstein@lite:~/build/ccsync$ time: 18790 ms\n>>> rsync alpha→beta: done (code 0)\n>>> rsync beta→alpha (/home/wstein/scratch/y -> /home/wstein/scratch/x)\n$ rsync -a -I --relative --whole-file --from0 --files-from=/tmp/sync-plan-6EOP5R/toAlpha.list /home/wstein/scratch/y/ /home/wstein/scratch/x/\ntime: 57 ms\n>>> rsync beta→alpha: done (code 0)\n[phase] rsync: 3) copy files: 18848 ms\n[phase] rsync: 4) delete dirs: running...\nrsync's all done, now updating database\n[phase] post rsync database update: running...\n[plan] insert plan tables: 39 ms\nPlan table counts: to_beta=76571 to_alpha=4 del_beta=0 del_alpha=0\nPlan dir counts   : d_to_beta=7202 d_to_alpha=3 d_del_beta=0 d_del_alpha=0\n[phase] post rsync database update: 383 ms\n[phase] drop tombstones: running...\n[phase] drop tombstones: 28 ms\n[phase] sqlite hygiene: running...\nMerge complete.\n```\n\n","done":true,"last_edited":1761626544087,"position":-6.8125,"task_id":"1c1add8a-cbb5-4ef8-8a55-b2905a4935b0"}
{"desc":"don't run hot updates while full sync cycle is running??\n\ndoing this could be very weird annoying for users since updates switch from being instant to suddenly being really slow.  So NO, do NOT do this.  This is supposed to be realtime.\n\n- right now things utterly go to hell if hot watch is enabled for a remote server, and we copy in a built cocalc, then keep moving it to stress.  files start vanishing from the remote.  It's very bad.\n- I think that the entire scan process must work with arbitrary file activity happening on either side, and no assumptions about that.\n- It's only when file activity stops that sync is guaranteed to lead to a consistent filesystem with our rules.\n\n","done":true,"hideBody":true,"last_edited":1761771319418,"position":0.625,"task_id":"fff0fe9e-7524-4348-8797-8f724c56109f"}
{"desc":"fix digest\n","done":true,"last_edited":1761543649925,"position":-5.4375,"task_id":"32a0a959-17f4-4273-ae11-eccd8ed4db16"}
{"desc":"ignore\n\n- [x] don't watch ignored files\n- [x] don't scan ignored files\n\n","done":true,"last_edited":1761458990155,"position":-1,"task_id":"74fd2541-de8c-4a8a-ac43-5e3fa3d283dc"}
{"desc":"location of remote db in scheduler needs to be more sensible:\n\n```\n      // use same path as local DB, but on remote:\n      // [ ] TODO: this isn't going to be right in general!\n      \"--db\",\n      params.localDb,\n```\n\n","done":true,"last_edited":1761771761672,"position":-19.3125,"task_id":"3ec6f5c2-d245-4e43-b599-c0be361cdd80"}
{"desc":"propagate mode\\-only change \\(chmod \\+x\\) without content change\n","done":true,"last_edited":1761540700065,"position":-4.9375,"task_id":"9fdef768-cf20-425c-838c-ab1fe219afde"}
{"desc":"remote scan \\-\\- why does it output _everything_ every time?   that seems very inefficient.  It should output only the records of the database that change, right?\n\n#WORRY  if the remote scan isn't properly fully ingested then the local and remote beta.db are forever in an inconsistent state. \n\nBut right now since we're getting everything every time, it doesn't matter.  But that's pretty wrong.\n\n","done":true,"last_edited":1761720532007,"position":-21.4375,"task_id":"4be0a2f5-fb80-443c-aae9-8bcf5a66f1f6"}
{"desc":"symlinks to directories get turned into directories by sync\n","done":true,"last_edited":1761626504801,"position":-9.8125,"task_id":"d330133e-42c8-4380-b73f-ddb949f99d1b"}
{"desc":"when creating a session, tilde ~ expansion on remote doesn't properly work \\-\\- need to ssh and figure out HOME once\n","done":true,"last_edited":1761771328203,"position":-29.4375,"task_id":"f005f6c8-8a06-4fc2-a0ca-71b96d86c86f"}